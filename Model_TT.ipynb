{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# keras with image MNIST"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## pylibs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import cv2\n",
    "import keras\n",
    "import random\n",
    "import datetime\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.ndimage import zoom\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.optimizers import SGD\n",
    "from keras.regularizers import l2\n",
    "from keras.models import load_model\n",
    "from matplotlib import pyplot as plt\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "from keras.models import Model\n",
    "from keras import Sequential\n",
    "from random import randint, choice\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.callbacks import TensorBoard\n",
    "from keras.utils import to_categorical\n",
    "from keras.callbacks import Callback\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization, AveragePooling2D, MaxPooling1D, Conv1D, Reshape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
    "#more info on https://github.com/Aydinhamedi/Python-color-print/tree/main\n",
    "#!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
    "def print_Color(Input: str, colors: list, print_END: str = '\\n', advanced_mode: bool = False):\n",
    "    \"\"\"\n",
    "    Prints colored text to the console using advanced terminal colors.\n",
    "\n",
    "    Args:\n",
    "        Input (str): The input string to be printed. In advanced mode, '~*' is used to separate different parts of the string to be printed in different colors.\n",
    "        colors (list): A list of colors for the text. In non-advanced mode, only the first color in the list is used. In advanced mode, each color corresponds to a part of the input string separated by '~*'.\n",
    "        print_END (str): The string appended after the final output. Default is '\\\\n'.\n",
    "        advanced_mode (bool): If True, enables advanced mode that allows multiple colors in one string. Default is False.\n",
    "\n",
    "    Examples:\n",
    "    ~~~python\n",
    "        print_Color('Hello, World!', ['green']) \n",
    "        # Prints 'Hello, World!' in green.\n",
    "\n",
    "        print_Color('~*Hello in green~*Hello in red', ['green', 'red'], advanced_mode=True) \n",
    "        # Prints 'Hello in green' in green and 'Hello in red' in red.\n",
    "\n",
    "    Note:\n",
    "        The advanced terminal colors can be used by providing the escape sequences directly in the colors list.\n",
    "        If an invalid color is provided, an error message will be printed.\n",
    "    \"\"\"\n",
    "    color_code = {\n",
    "        'black': '\\x1b[0;30m',\n",
    "        'red': '\\x1b[0;31m',\n",
    "        'green': '\\x1b[0;32m',\n",
    "        'yellow': '\\x1b[0;33m',\n",
    "        'blue': '\\x1b[0;34m',\n",
    "        'magenta': '\\x1b[0;35m',\n",
    "        'cyan': '\\x1b[0;36m',\n",
    "        'white': '\\x1b[0;37m',\n",
    "        'normal': '\\x1b[0m',\n",
    "        'bg_black': '\\x1b[40m',\n",
    "        'bg_red': '\\x1b[41m',\n",
    "        'bg_green': '\\x1b[42m',\n",
    "        'bg_yellow': '\\x1b[43m',\n",
    "        'bg_blue': '\\x1b[44m',\n",
    "        'bg_magenta': '\\x1b[45m',\n",
    "        'bg_cyan': '\\x1b[46m',\n",
    "        'bg_white': '\\x1b[47m',\n",
    "        'bg_normal': '\\x1b[49m',\n",
    "        'light_gray': '\\x1b[0;90m',\n",
    "        'light_red': '\\x1b[0;91m',\n",
    "        'light_green': '\\x1b[0;92m',\n",
    "        'light_yellow': '\\x1b[0;93m',\n",
    "        'light_blue': '\\x1b[0;94m',\n",
    "        'light_magenta': '\\x1b[0;95m',\n",
    "        'light_cyan': '\\x1b[0;96m',\n",
    "        'light_white': '\\x1b[0;97m',\n",
    "        'bg_light_gray': '\\x1b[0;100m',\n",
    "        'bg_light_red': '\\x1b[0;101m',\n",
    "        'bg_light_green': '\\x1b[0;102m',\n",
    "        'bg_light_yellow': '\\x1b[0;103m',\n",
    "        'bg_light_blue': '\\x1b[0;104m',\n",
    "        'bg_light_magenta': '\\x1b[0;105m',\n",
    "        'bg_light_cyan': '\\x1b[0;106m',\n",
    "        'bg_light_white': '\\x1b[0;107m',\n",
    "        'bold': '\\x1b[1m',\n",
    "        'underline': '\\x1b[4m',\n",
    "        'blink': '\\x1b[5m'\n",
    "    }\n",
    "\n",
    "    if not advanced_mode:\n",
    "        if colors[0] in color_code:\n",
    "            print(color_code[colors[0]] + Input + '\\x1b[0m', end=print_END)\n",
    "        else:\n",
    "            print(\"[print_Color] ERROR: Invalid color input!!!\")\n",
    "    else:\n",
    "        substrings = Input.split('~*')\n",
    "        if len(substrings) != len(colors) + 1:\n",
    "            print(\"[print_Color] ERROR: Number of colors and number of '~*' don't match!!!\")\n",
    "        else:\n",
    "            for sub_str, color in zip(substrings, ['normal'] + colors):\n",
    "                if color in color_code:\n",
    "                    print(color_code[color] + sub_str + '\\x1b[0m', end='')\n",
    "                else:\n",
    "                    print(f\"\\n[print_Color] ERROR: Invalid color!!! The input color: '{color}' input list index: {colors.index(color)}\")\n",
    "            print('', end=print_END)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## data processing with image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GEN_IMG_COUNT = 40000\n",
    "SIF_ARG = 0\n",
    "SIF_GEN = 0\n",
    "SIF_TEST = 0\n",
    "SIF_TEST_TVS = 0\n",
    "ADG_VM = False\n",
    "DDA = 3\n",
    "#data_augmentation\n",
    "def data_augmentation(image):\n",
    "    new_image = np.zeros_like(image)\n",
    "    # Resize image to a random size between 22 and 28\n",
    "    new_size = np.random.randint(22, 28)\n",
    "    image = zoom(image, (new_size / image.shape[0], new_size / image.shape[1], 1))\n",
    "    pad_size = (np.random.randint(1, 20), np.random.randint(1, 20))\n",
    "    # Choose a random side or corner to pad from\n",
    "    side_or_corner = np.random.choice(['top', 'bottom', 'left', 'right', 'top-left', 'top-right', 'bottom-left', 'bottom-right', 'AD'])\n",
    "\n",
    "    # Set the padding size based on the chosen side or corner\n",
    "    if side_or_corner == 'top':\n",
    "        pad_size = ((pad_size[0], 0), (0, 0), (0, 0))\n",
    "    elif side_or_corner == 'bottom':\n",
    "        pad_size = ((0, pad_size[0]), (0, 0), (0, 0))\n",
    "    elif side_or_corner == 'left':\n",
    "        pad_size = ((0, 0), (pad_size[1], 0), (0, 0))\n",
    "    elif side_or_corner == 'right':\n",
    "        pad_size = ((0, 0), (0, pad_size[1]), (0, 0))\n",
    "    elif side_or_corner == 'top-left':\n",
    "        pad_size = ((pad_size[0], 0), (pad_size[1], 0), (0, 0))\n",
    "    elif side_or_corner == 'top-right':\n",
    "        pad_size = ((pad_size[0], 0), (0, pad_size[1]), (0, 0))\n",
    "    elif side_or_corner == 'bottom-left':\n",
    "        pad_size = ((0, pad_size[0]), (pad_size[1], 0), (0, 0))\n",
    "    elif side_or_corner == 'bottom-right':\n",
    "        pad_size = ((0, pad_size[0]), (0, pad_size[1]), (0, 0))\n",
    "    else: #'AD'\n",
    "        pad_size = ((pad_size[1], pad_size[1]), (pad_size[1], pad_size[1]), (0, 0))\n",
    "        \n",
    "    padded_image = np.pad(image, pad_size, mode='constant')\n",
    "\n",
    "    new_image = padded_image\n",
    "    image = new_image\n",
    "    \n",
    "    resized_image = cv2.resize(image, (28, 28))\n",
    "    image = resized_image[:, :, np.newaxis]\n",
    "    new_image = image\n",
    "    \n",
    "    crop_size = np.random.randint(23, 28)\n",
    "    # Choose a random direction\n",
    "    direction = np.random.choice(['up', 'down', 'left', 'right'])\n",
    "\n",
    "    # Set the starting position of the cropped image based on the chosen direction\n",
    "    if direction == 'up':\n",
    "        start_x = np.random.randint(0, image.shape[1] - crop_size)\n",
    "        start_y = 0\n",
    "    elif direction == 'down':\n",
    "        start_x = np.random.randint(0, image.shape[1] - crop_size)\n",
    "        start_y = image.shape[0] - crop_size\n",
    "    elif direction == 'left':\n",
    "        start_x = 0\n",
    "        start_y = np.random.randint(0, image.shape[0] - crop_size)\n",
    "    else:  # 'right'\n",
    "        start_x = image.shape[1] - crop_size\n",
    "        start_y = np.random.randint(0, image.shape[0] - crop_size)\n",
    "\n",
    "    # Crop the image\n",
    "    cropped_image = image[start_y:start_y+crop_size, start_x:start_x+crop_size]\n",
    "\n",
    "    image = cropped_image\n",
    "    new_image = image\n",
    "    resized_image = cv2.resize(image, (28, 28))\n",
    "    image = resized_image[:, :, np.newaxis]\n",
    "    new_image = image\n",
    "    for i in range(np.random.randint(0, 12)):\n",
    "        image_copy = image.copy()  # Create a copy of the original image\n",
    "        height, width = image_copy.shape[0], image_copy.shape[1]\n",
    "        x1, y1 = np.random.randint(0, width), np.random.randint(0, height)\n",
    "        x2, y2 = np.random.randint(0, width), np.random.randint(0, height)\n",
    "\n",
    "        color = (random.uniform(0.1, 1), random.uniform(0.1, 1), random.uniform(0.1, 1))  # RGB color\n",
    "        thickness = np.random.randint(1, 2)  # Random thickness\n",
    "\n",
    "        cv2.line(image_copy, (x1, y1), (x2, y2), color, thickness)\n",
    "        image = image_copy\n",
    "    new_image = image\n",
    "    noise_func = np.random.choice(['L1', 'L2', 'L3', 'none'])\n",
    "    if noise_func == 'L3':\n",
    "        intensityL2 = random.uniform(0.1, 0.15)\n",
    "        intensityL1 = random.uniform(0.1, 0.15)\n",
    "    else:\n",
    "        intensityL2 = random.uniform(0.1, 0.25)\n",
    "        intensityL1 = random.uniform(0.1, 0.25)\n",
    "    if noise_func == 'L2' or noise_func == 'L3':\n",
    "        for i in range(0, image.shape[0], 4):\n",
    "            for j in range(0, image.shape[1], 4):\n",
    "                block = image[i:i+4, j:j+4]\n",
    "                block = (np.random.rand() * intensityL2 + 1) * block\n",
    "                new_image[i:i+4, j:j+4] = block\n",
    "        image = new_image      \n",
    "    elif noise_func == 'L1' or noise_func == 'L3': \n",
    "        for i in range(0, image.shape[0], 2):\n",
    "            for j in range(0, image.shape[1], 2):\n",
    "                block = image[i:i+2, j:j+2]\n",
    "                block = (np.random.rand() * intensityL1 + 1) * block\n",
    "                new_image[i:i+2, j:j+2] = block\n",
    "    return new_image\n",
    "#data_augmentation_TVS (DO NOT CHANGE)\n",
    "def data_augmentation_TVS(image):\n",
    "    new_image = np.zeros_like(image)\n",
    "    # Resize image to a random size between 22 and 28\n",
    "    new_size = np.random.randint(22, 28)\n",
    "    image = zoom(image, (new_size / image.shape[0], new_size / image.shape[1], 1))\n",
    "    pad_size = (np.random.randint(1, 20), np.random.randint(1, 20))\n",
    "    # Choose a random side or corner to pad from\n",
    "    side_or_corner = np.random.choice(['top', 'bottom', 'left', 'right', 'top-left', 'top-right', 'bottom-left', 'bottom-right', 'AD'])\n",
    "\n",
    "    # Set the padding size based on the chosen side or corner\n",
    "    if side_or_corner == 'top':\n",
    "        pad_size = ((pad_size[0], 0), (0, 0), (0, 0))\n",
    "    elif side_or_corner == 'bottom':\n",
    "        pad_size = ((0, pad_size[0]), (0, 0), (0, 0))\n",
    "    elif side_or_corner == 'left':\n",
    "        pad_size = ((0, 0), (pad_size[1], 0), (0, 0))\n",
    "    elif side_or_corner == 'right':\n",
    "        pad_size = ((0, 0), (0, pad_size[1]), (0, 0))\n",
    "    elif side_or_corner == 'top-left':\n",
    "        pad_size = ((pad_size[0], 0), (pad_size[1], 0), (0, 0))\n",
    "    elif side_or_corner == 'top-right':\n",
    "        pad_size = ((pad_size[0], 0), (0, pad_size[1]), (0, 0))\n",
    "    elif side_or_corner == 'bottom-left':\n",
    "        pad_size = ((0, pad_size[0]), (pad_size[1], 0), (0, 0))\n",
    "    elif side_or_corner == 'bottom-right':\n",
    "        pad_size = ((0, pad_size[0]), (0, pad_size[1]), (0, 0))\n",
    "    else: #'AD'\n",
    "        pad_size = ((pad_size[1], pad_size[1]), (pad_size[1], pad_size[1]), (0, 0))\n",
    "        \n",
    "    padded_image = np.pad(image, pad_size, mode='constant')\n",
    "\n",
    "    new_image = padded_image\n",
    "    image = new_image\n",
    "    \n",
    "    resized_image = cv2.resize(image, (28, 28))\n",
    "    image = resized_image[:, :, np.newaxis]\n",
    "    new_image = image\n",
    "    \n",
    "    crop_size = np.random.randint(23, 28)\n",
    "    # Choose a random direction\n",
    "    direction = np.random.choice(['up', 'down', 'left', 'right'])\n",
    "\n",
    "    # Set the starting position of the cropped image based on the chosen direction\n",
    "    if direction == 'up':\n",
    "        start_x = np.random.randint(0, image.shape[1] - crop_size)\n",
    "        start_y = 0\n",
    "    elif direction == 'down':\n",
    "        start_x = np.random.randint(0, image.shape[1] - crop_size)\n",
    "        start_y = image.shape[0] - crop_size\n",
    "    elif direction == 'left':\n",
    "        start_x = 0\n",
    "        start_y = np.random.randint(0, image.shape[0] - crop_size)\n",
    "    else:  # 'right'\n",
    "        start_x = image.shape[1] - crop_size\n",
    "        start_y = np.random.randint(0, image.shape[0] - crop_size)\n",
    "\n",
    "    # Crop the image\n",
    "    cropped_image = image[start_y:start_y+crop_size, start_x:start_x+crop_size]\n",
    "\n",
    "    image = cropped_image\n",
    "    new_image = image\n",
    "    resized_image = cv2.resize(image, (28, 28))\n",
    "    image = resized_image[:, :, np.newaxis]\n",
    "    new_image = image\n",
    "    for i in range(np.random.randint(0, 12)):\n",
    "        image_copy = image.copy()  # Create a copy of the original image\n",
    "        height, width = image_copy.shape[0], image_copy.shape[1]\n",
    "        x1, y1 = np.random.randint(0, width), np.random.randint(0, height)\n",
    "        x2, y2 = np.random.randint(0, width), np.random.randint(0, height)\n",
    "\n",
    "        color = (random.uniform(0.1, 1), random.uniform(0.1, 1), random.uniform(0.1, 1))  # RGB color\n",
    "        thickness = np.random.randint(1, 2)  # Random thickness\n",
    "\n",
    "        cv2.line(image_copy, (x1, y1), (x2, y2), color, thickness)\n",
    "        image = image_copy\n",
    "    new_image = image\n",
    "    noise_func = np.random.choice(['L1', 'L2', 'L3', 'none'])\n",
    "    if noise_func == 'L3':\n",
    "        intensityL2 = random.uniform(0.01, 0.2)\n",
    "        intensityL1 = random.uniform(0.01, 0.2)\n",
    "    else:\n",
    "        intensityL2 = random.uniform(0.01, 0.35)\n",
    "        intensityL1 = random.uniform(0.01, 0.35)\n",
    "    if noise_func == 'L2' or noise_func == 'L3':\n",
    "        for i in range(0, image.shape[0], 4):\n",
    "            for j in range(0, image.shape[1], 4):\n",
    "                block = image[i:i+4, j:j+4]\n",
    "                block = (np.random.rand() * intensityL2 + 1) * block\n",
    "                new_image[i:i+4, j:j+4] = block\n",
    "        image = new_image      \n",
    "    elif noise_func == 'L1' or noise_func == 'L3': \n",
    "        for i in range(0, image.shape[0], 2):\n",
    "            for j in range(0, image.shape[1], 2):\n",
    "                block = image[i:i+2, j:j+2]\n",
    "                block = (np.random.rand() * intensityL1 + 1) * block\n",
    "                new_image[i:i+2, j:j+2] = block\n",
    "    return new_image\n",
    "#save_images_to_dir\n",
    "def save_images_to_dir(images, labels, dir_path):\n",
    "    # create the directory if it doesn't exist\n",
    "    if not os.path.exists(dir_path):\n",
    "        os.makedirs(dir_path)\n",
    "    # iterate over the images and labels\n",
    "    for i, (image, label) in enumerate(zip(images, labels)):\n",
    "        # only save every 10th image\n",
    "        if i % 10 == 0:\n",
    "            # get the class label\n",
    "            class_label = np.argmax(label)\n",
    "            # create the file path\n",
    "            file_path = os.path.join(dir_path, f'image_{i}_class_{class_label}.png')\n",
    "            # save the image to the file path\n",
    "            plt.imsave(file_path, image.squeeze(), cmap='gray')\n",
    "print('loading Dataset...')\n",
    "# load dataset\n",
    "with np.load('mnist.npz') as data:\n",
    "    x_train, y_train = data['x_train'], data['y_train']\n",
    "    x_test, y_test = data['x_test'], data['y_test']\n",
    "\n",
    "# reshape dataset to have a single channel\n",
    "x_train = x_train.reshape((x_train.shape[0], 28, 28, 1))\n",
    "x_test = x_test.reshape((x_test.shape[0], 28, 28, 1))\n",
    "\n",
    "# one hot encode target values\n",
    "y_train = to_categorical(y_train)\n",
    "y_test = to_categorical(y_test)\n",
    "\n",
    "#gen img\n",
    "def generate_image(number, font):\n",
    "    img = Image.new('L', (28, 28), color=random.randint(50, 240))\n",
    "    number_color = random.randint(180, 255)\n",
    "    draw = ImageDraw.Draw(img)\n",
    "    \n",
    "    # Drawing number\n",
    "    text_length = font.getlength(str(number))\n",
    "    x_offset = random.randint(-8, 8)  # Generate a random offset between -8 and 8 for x\n",
    "    y_offset = random.randint(-8, 8)  # Generate a random offset between -8 and 8 for y\n",
    "    x = (img.width - text_length) // 2 + x_offset\n",
    "    y = (img.height - font.size) // 2 + y_offset\n",
    "    draw.text((x, y), str(number), font=font, fill=number_color)\n",
    "    \n",
    "    # Drawing lines\n",
    "    num_lines = random.randint(0, 10)\n",
    "    for _ in range(num_lines):\n",
    "        start = (random.randint(0, img.width-1), random.randint(0, img.height-1))\n",
    "        end = (random.randint(0, img.width-1), random.randint(0, img.height-1))\n",
    "        line_width = random.randint(1, 2)\n",
    "        line_color = random.randint(0, 255);  # Random grayscale value\n",
    "        draw.line([start, end], fill=line_color, width=line_width)\n",
    "    \n",
    "    return np.expand_dims(np.array(img), axis=-1)\n",
    "\n",
    "\n",
    "fonts = [\n",
    "    ImageFont.truetype('arial.ttf', random.randint(6, 28)),\n",
    "    ImageFont.truetype('times.ttf', random.randint(6, 28)),\n",
    "    ImageFont.truetype('calibri.ttf', random.randint(6, 28)),\n",
    "    ImageFont.truetype('comic.ttf', random.randint(6, 28)),\n",
    "    ImageFont.truetype('georgia.ttf', random.randint(6, 28)),\n",
    "    ImageFont.truetype('impact.ttf', random.randint(6, 28)),\n",
    "    ImageFont.truetype('tahoma.ttf', random.randint(6, 28)),\n",
    "    ImageFont.truetype('verdana.ttf', random.randint(6, 28)),\n",
    "]\n",
    "print('Generating extra imgs...')\n",
    "numbers = [randint(0, 9) for _ in range(GEN_IMG_COUNT)]\n",
    "images = [generate_image(number, choice(fonts)) for number in numbers]\n",
    "\n",
    "GEN_IMG_x_train, GEN_IMG_x_test, GEN_IMG_y_train, GEN_IMG_y_test = train_test_split(images, numbers, test_size=0.20)\n",
    "GEN_IMG_y_train = to_categorical(GEN_IMG_y_train, num_classes=10)\n",
    "GEN_IMG_y_test = to_categorical(GEN_IMG_y_test, num_classes=10)\n",
    "\n",
    "x_train = np.concatenate([x_train, GEN_IMG_x_train])\n",
    "y_train = np.concatenate([y_train, GEN_IMG_y_train])\n",
    "x_test = np.concatenate([x_test, GEN_IMG_x_test])\n",
    "y_test = np.concatenate([y_test, GEN_IMG_y_test])\n",
    "# data processing\n",
    "x_train = x_train.astype('float32') / 255\n",
    "x_test = x_test.astype('float32') / 255\n",
    "#summarize_datagen func\n",
    "def summarize_datagen(datagen):\n",
    "    print('ImageDataGenerator Conf:')\n",
    "    config = datagen.__dict__\n",
    "    for key, value in config.items():\n",
    "        print(f\">   {key}: {value}\")\n",
    "\n",
    "# create a data generator\n",
    "#train\n",
    "datagen = ImageDataGenerator(rotation_range=20,\n",
    "                             horizontal_flip=False,\n",
    "                             zoom_range = 0.15, \n",
    "                             width_shift_range=0.1, \n",
    "                             height_shift_range=0.1,\n",
    "                             #brightness_range=(0.95,1.05),\n",
    "                             preprocessing_function=lambda x: data_augmentation(1-x))\n",
    "#TVS (DO NOT CHANGE)\n",
    "datagen_TVS = ImageDataGenerator(rotation_range=20,\n",
    "                                 horizontal_flip=False,\n",
    "                                 zoom_range = 0.15, \n",
    "                                 width_shift_range=0.1, \n",
    "                                 height_shift_range=0.1,\n",
    "                                 #brightness_range=(0.95,1.05),\n",
    "                                 preprocessing_function=lambda x: data_augmentation_TVS(1-x))\n",
    "if ADG_VM: \n",
    "    summarize_datagen(datagen)\n",
    "    summarize_datagen(datagen_TVS)    \n",
    "#GAD_TVS\n",
    "print(f'Generating augmented data TVS [DDA: 3]...')\n",
    "for i in range(3):\n",
    "    print(f'>   Generating ADB TVS [{i}]...')\n",
    "    # prepare an iterators to scale images\n",
    "    test_iterator_TVS = datagen_TVS.flow(x_test, y_test, batch_size=len(x_test))\n",
    "\n",
    "    # get augmented data\n",
    "    x_test_augmented, y_test_augmented = test_iterator_TVS.next()\n",
    "    \n",
    "    print(f'>   \\---Adding the Generated ADB TVS...')\n",
    "    # append augmented data to original data\n",
    "    x_test = np.concatenate([x_test, x_test_augmented])\n",
    "    y_test = np.concatenate([y_test, y_test_augmented])\n",
    "#GAD_train\n",
    "print(f'Generating augmented data [DDA: {str(DDA)}]...')\n",
    "if DDA > 0:\n",
    "    for i in range(DDA):\n",
    "        print(f'>   Generating ADB[{i}]...')\n",
    "        # prepare an iterators to scale images\n",
    "        train_iterator = datagen.flow(x_train, y_train, batch_size=len(x_train))\n",
    "\n",
    "        # get augmented data\n",
    "        x_train_augmented, y_train_augmented = train_iterator.next()\n",
    "        \n",
    "        print(f'>   \\---Adding the Generated ADB...')\n",
    "        # append augmented data to original data\n",
    "        x_train = np.concatenate([x_train, x_train_augmented])\n",
    "        y_train = np.concatenate([y_train, y_train_augmented])\n",
    "else:\n",
    "    print('>    Replacing data with augmented data...')\n",
    "    # prepare an iterators to scale images\n",
    "    train_iterator = datagen.flow(x_train, y_train, batch_size=len(x_train))\n",
    "\n",
    "    # get augmented data\n",
    "    x_train_augmented, y_train_augmented = train_iterator.next()\n",
    "    \n",
    "    # append augmented data to original data\n",
    "    x_train =  x_train_augmented\n",
    "    y_train =  y_train_augmented\n",
    "#STS\n",
    "print('Saving test samples...')\n",
    "# save augmented data to directories\n",
    "if SIF_ARG:\n",
    "    print('>    Saving [test_TS_ARG]...')\n",
    "    save_images_to_dir(x_train_augmented, y_train_augmented, 'test_TS_ARG')\n",
    "if SIF_GEN:\n",
    "    print('>    Saving [test_TS_GEN]...')\n",
    "    save_images_to_dir(GEN_IMG_x_train, GEN_IMG_y_train, 'test_TS_GEN')\n",
    "if SIF_TEST:\n",
    "    print('>    Saving [test_TS]...')\n",
    "    save_images_to_dir(x_train, y_train, 'test_TS')\n",
    "if SIF_TEST_TVS:\n",
    "    print('>    Saving [test_TS_TVS]...')\n",
    "    save_images_to_dir(x_test, y_test, 'test_TS_TVS')\n",
    "print('verbose: ')\n",
    "print(f'>   Train len: {x_train.shape[0]:,}')\n",
    "print(f'>   Test TVS len: {x_test.shape[0]:,}')\n",
    "print('done.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "#Feature Extaction Size=28x28\n",
    "model.add(Conv2D(64, (4, 4), activation='relu', padding='same', name='block1_conv1', input_shape=(28, 28, 1)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(64, (4, 4), activation='relu', padding='same', name='block1_conv2'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(64, (4, 4), activation='relu', padding='same', name='block1_conv3'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D((2, 2), strides=(2, 2), name='block1_pool'))\n",
    "#_LFE(Large Feature Extaction) Size=14x14\n",
    "model.add(Conv2D(128, (5, 5), activation='relu', padding='same', name='block2_conv1_LFE'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Conv2D(128, (5, 5), activation='relu', padding='same', name='block2_conv2_LFE'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Conv2D(128, (5, 5), activation='relu', padding='same', name='block2_conv3_LFE'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Conv2D(128, (5, 5), activation='relu', padding='same', name='block2_conv4_LFE'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.25))\n",
    "model.add(MaxPooling2D((2, 2), strides=(2, 2), name='block2_pool'))\n",
    "#Feature Extaction Size=7x7\n",
    "model.add(Conv2D(256, (3, 3), activation='relu', padding='same', name='block4_conv1'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.35))\n",
    "model.add(Conv2D(256, (3, 3), activation='relu', padding='same', name='block4_conv2'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.35))\n",
    "model.add(Conv2D(256, (3, 3), activation='relu', padding='same', name='block4_conv3'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.35))\n",
    "#Feature Extaction Size=7x7\n",
    "model.add(Conv2D(512, (2, 2), activation='relu', padding='same', name='block5_conv1'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.4))\n",
    "model.add(Conv2D(512, (2, 2), activation='relu', padding='same', name='block5_conv2'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.4))\n",
    "model.add(Conv2D(512, (2, 2), activation='relu', padding='same', name='block5_conv3'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.4))\n",
    "model.add(MaxPooling2D((2, 2), strides=(2, 2), name='block5_pool'))\n",
    "#Feature Extaction Size=3x3\n",
    "model.add(Conv2D(512, (1, 1), activation='relu', padding='same', name='block6_conv1'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.4))\n",
    "model.add(Conv2D(512, (1, 1), activation='relu', padding='same', name='block6_conv2'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.4))\n",
    "model.add(Conv2D(512, (1, 1), activation='relu', padding='same', name='block6_conv3'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.4))\n",
    "#Flatten\n",
    "model.add(Flatten(name='flatten1'))\n",
    "#Feature Classifier\n",
    "model.add(Dense(512, activation='relu', name='fc1', kernel_regularizer=l2(0.1)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dense(512, activation='relu', name='fc2', kernel_regularizer=l2(0.1)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dense(10, activation='softmax', name='predictions'))\n",
    "# compile model\n",
    "opt = SGD(learning_rate=0.01, momentum=0.9)\n",
    "model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "#summary\n",
    "model.summary()\n",
    "#end\n",
    "print('\\nThe model was successfully created')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## loading the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    model = load_model('MNIST_model.h5')\n",
    "except (ImportError, IOError) as e:\n",
    "    print_Color(f'failed to load the model ERROR:\\n>  {e}', ['red'])\n",
    "else:\n",
    "    print_Color('loading model done.', ['green'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#early_stopping\n",
    "early_stopping = EarlyStopping(monitor='val_accuracy', patience=8, verbose=1, restore_best_weights = True)\n",
    "#visualizer\n",
    "log_dir = \"logs/fit/\" + datetime.datetime.now().strftime(\"y%Y_m%m_d%d-h%H_m%M_s%S\")\n",
    "tensorboard_callback = TensorBoard(log_dir=log_dir, write_images=False, histogram_freq=1)\n",
    "print_Color(f'Log dir: ~*{log_dir}', ['yellow'], advanced_mode=True)\n",
    "print_Color('Training the model...\\n', ['white'])\n",
    "try:\n",
    "    history = model.fit(x_train, y_train, epochs=256, batch_size=32, validation_data=(x_test, y_test), verbose='auto', callbacks=[early_stopping, tensorboard_callback])\n",
    "except KeyboardInterrupt:\n",
    "    print_Color('\\nTraining stopped!', ['red'])\n",
    "else:\n",
    "    print_Color('Training done.\\n', ['green'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving model weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('MNIST_model.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyzing the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    #loss\n",
    "    plt.plot(history.history['loss'], label='loss')\n",
    "    try:\n",
    "        plt.plot(history.history['val_loss'], label='val_loss', color='orange')\n",
    "    except (ValueError, NameError):\n",
    "        print_Color('failed to load val_loss.', ['red'])\n",
    "    plt.title('Model Loss')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.show()\n",
    "    #acc\n",
    "    plt.plot(history.history['accuracy'], label='accuracy')\n",
    "    try:\n",
    "        plt.plot(history.history['val_accuracy'], label='val_accuracy', color='orange')\n",
    "    except (ValueError, NameError):\n",
    "        print_Color('failed to load val_accuracy.', ['red'])\n",
    "    plt.title('Model Accuracy')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.show()\n",
    "except (ValueError, NameError):\n",
    "    print_Color('failed to load model history.', ['red'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
